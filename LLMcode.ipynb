{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this project is heavely derived from the book Build a \n",
    "# Large Language model(from scratch) by Sebastian Raschka and \n",
    "# a youtube playlist from vizuara\n",
    "# checkout their playlist here ->\n",
    "# https://www.youtube.com/playlist?list=PLPTV0NXA_ZSgsLAr8YCgCwhPIJNNtexWu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first step is to tokenize the text for llm training\n",
    "# we can use re.split() command for doing so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hellow', ',', '', ' ', 'world', ' ', '', '!', '', ' ', 'ho', ' ', 'w', ' ', 'are', ' ', 'u', '?', '']\n"
     ]
    }
   ],
   "source": [
    "text = 'hellow, world ! ho w are u?'\n",
    "result = re.split(r'([,!@#$%^&*\"(){}?:<>+=_./]|--|\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hellow', ',', 'world', '!', 'ho', 'w', 'are', 'u', '?']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we got a basic tokenizer working, \n",
    "# let's apply it to Edith Wharton's entire short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to create token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the vocabulary size is 1130, we create a vocabulary\n",
    "# of the format token:ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer, token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 0,\n",
       " '\"': 1,\n",
       " \"'\": 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " ',': 5,\n",
       " '--': 6,\n",
       " '.': 7,\n",
       " ':': 8,\n",
       " ';': 9,\n",
       " '?': 10,\n",
       " 'A': 11,\n",
       " 'Ah': 12,\n",
       " 'Among': 13,\n",
       " 'And': 14,\n",
       " 'Are': 15,\n",
       " 'Arrt': 16,\n",
       " 'As': 17,\n",
       " 'At': 18,\n",
       " 'Be': 19,\n",
       " 'Begin': 20,\n",
       " 'Burlington': 21,\n",
       " 'But': 22,\n",
       " 'By': 23,\n",
       " 'Carlo': 24,\n",
       " 'Chicago': 25,\n",
       " 'Claude': 26,\n",
       " 'Come': 27,\n",
       " 'Croft': 28,\n",
       " 'Destroyed': 29,\n",
       " 'Devonshire': 30,\n",
       " 'Don': 31,\n",
       " 'Dubarry': 32,\n",
       " 'Emperors': 33,\n",
       " 'Florence': 34,\n",
       " 'For': 35,\n",
       " 'Gallery': 36,\n",
       " 'Gideon': 37,\n",
       " 'Gisburn': 38,\n",
       " 'Gisburns': 39,\n",
       " 'Grafton': 40,\n",
       " 'Greek': 41,\n",
       " 'Grindle': 42,\n",
       " 'Grindles': 43,\n",
       " 'HAD': 44,\n",
       " 'Had': 45,\n",
       " 'Hang': 46,\n",
       " 'Has': 47,\n",
       " 'He': 48,\n",
       " 'Her': 49,\n",
       " 'Hermia': 50,\n",
       " 'His': 51,\n",
       " 'How': 52,\n",
       " 'I': 53,\n",
       " 'If': 54,\n",
       " 'In': 55,\n",
       " 'It': 56,\n",
       " 'Jack': 57,\n",
       " 'Jove': 58,\n",
       " 'Just': 59,\n",
       " 'Lord': 60,\n",
       " 'Made': 61,\n",
       " 'Miss': 62,\n",
       " 'Money': 63,\n",
       " 'Monte': 64,\n",
       " 'Moon-dancers': 65,\n",
       " 'Mr': 66,\n",
       " 'Mrs': 67,\n",
       " 'My': 68,\n",
       " 'Never': 69,\n",
       " 'No': 70,\n",
       " 'Now': 71,\n",
       " 'Nutley': 72,\n",
       " 'Of': 73,\n",
       " 'Oh': 74,\n",
       " 'On': 75,\n",
       " 'Once': 76,\n",
       " 'Only': 77,\n",
       " 'Or': 78,\n",
       " 'Perhaps': 79,\n",
       " 'Poor': 80,\n",
       " 'Professional': 81,\n",
       " 'Renaissance': 82,\n",
       " 'Rickham': 83,\n",
       " 'Riviera': 84,\n",
       " 'Rome': 85,\n",
       " 'Russian': 86,\n",
       " 'Sevres': 87,\n",
       " 'She': 88,\n",
       " 'Stroud': 89,\n",
       " 'Strouds': 90,\n",
       " 'Suddenly': 91,\n",
       " 'That': 92,\n",
       " 'The': 93,\n",
       " 'Then': 94,\n",
       " 'There': 95,\n",
       " 'They': 96,\n",
       " 'This': 97,\n",
       " 'Those': 98,\n",
       " 'Though': 99,\n",
       " 'Thwing': 100,\n",
       " 'Thwings': 101,\n",
       " 'To': 102,\n",
       " 'Usually': 103,\n",
       " 'Venetian': 104,\n",
       " 'Victor': 105,\n",
       " 'Was': 106,\n",
       " 'We': 107,\n",
       " 'Well': 108,\n",
       " 'What': 109,\n",
       " 'When': 110,\n",
       " 'Why': 111,\n",
       " 'Yes': 112,\n",
       " 'You': 113,\n",
       " '_': 114,\n",
       " 'a': 115,\n",
       " 'abdication': 116,\n",
       " 'able': 117,\n",
       " 'about': 118,\n",
       " 'above': 119,\n",
       " 'abruptly': 120,\n",
       " 'absolute': 121,\n",
       " 'absorbed': 122,\n",
       " 'absurdity': 123,\n",
       " 'academic': 124,\n",
       " 'accuse': 125,\n",
       " 'accustomed': 126,\n",
       " 'across': 127,\n",
       " 'activity': 128,\n",
       " 'add': 129,\n",
       " 'added': 130,\n",
       " 'admirers': 131,\n",
       " 'adopted': 132,\n",
       " 'adulation': 133,\n",
       " 'advance': 134,\n",
       " 'aesthetic': 135,\n",
       " 'affect': 136,\n",
       " 'afraid': 137,\n",
       " 'after': 138,\n",
       " 'afterward': 139,\n",
       " 'again': 140,\n",
       " 'ago': 141,\n",
       " 'ah': 142,\n",
       " 'air': 143,\n",
       " 'alive': 144,\n",
       " 'all': 145,\n",
       " 'almost': 146,\n",
       " 'alone': 147,\n",
       " 'along': 148,\n",
       " 'always': 149,\n",
       " 'am': 150,\n",
       " 'amazement': 151,\n",
       " 'amid': 152,\n",
       " 'among': 153,\n",
       " 'amplest': 154,\n",
       " 'amusing': 155,\n",
       " 'an': 156,\n",
       " 'and': 157,\n",
       " 'another': 158,\n",
       " 'answer': 159,\n",
       " 'answered': 160,\n",
       " 'any': 161,\n",
       " 'anything': 162,\n",
       " 'anywhere': 163,\n",
       " 'apparent': 164,\n",
       " 'apparently': 165,\n",
       " 'appearance': 166,\n",
       " 'appeared': 167,\n",
       " 'appointed': 168,\n",
       " 'are': 169,\n",
       " 'arm': 170,\n",
       " 'arm-chair': 171,\n",
       " 'arm-chairs': 172,\n",
       " 'arms': 173,\n",
       " 'art': 174,\n",
       " 'articles': 175,\n",
       " 'artist': 176,\n",
       " 'as': 177,\n",
       " 'aside': 178,\n",
       " 'asked': 179,\n",
       " 'at': 180,\n",
       " 'atmosphere': 181,\n",
       " 'atom': 182,\n",
       " 'attack': 183,\n",
       " 'attention': 184,\n",
       " 'attitude': 185,\n",
       " 'audacities': 186,\n",
       " 'away': 187,\n",
       " 'awful': 188,\n",
       " 'axioms': 189,\n",
       " 'azaleas': 190,\n",
       " 'back': 191,\n",
       " 'background': 192,\n",
       " 'balance': 193,\n",
       " 'balancing': 194,\n",
       " 'balustraded': 195,\n",
       " 'basking': 196,\n",
       " 'bath-rooms': 197,\n",
       " 'be': 198,\n",
       " 'beaming': 199,\n",
       " 'bean-stalk': 200,\n",
       " 'bear': 201,\n",
       " 'beard': 202,\n",
       " 'beauty': 203,\n",
       " 'became': 204,\n",
       " 'because': 205,\n",
       " 'becoming': 206,\n",
       " 'bed': 207,\n",
       " 'been': 208,\n",
       " 'before': 209,\n",
       " 'began': 210,\n",
       " 'begun': 211,\n",
       " 'behind': 212,\n",
       " 'being': 213,\n",
       " 'believed': 214,\n",
       " 'beneath': 215,\n",
       " 'bespoke': 216,\n",
       " 'better': 217,\n",
       " 'between': 218,\n",
       " 'big': 219,\n",
       " 'bits': 220,\n",
       " 'bitterness': 221,\n",
       " 'blocked': 222,\n",
       " 'born': 223,\n",
       " 'borne': 224,\n",
       " 'boudoir': 225,\n",
       " 'bravura': 226,\n",
       " 'break': 227,\n",
       " 'breaking': 228,\n",
       " 'breathing': 229,\n",
       " 'bric-a-brac': 230,\n",
       " 'briefly': 231,\n",
       " 'brings': 232,\n",
       " 'bronzes': 233,\n",
       " 'brought': 234,\n",
       " 'brown': 235,\n",
       " 'brush': 236,\n",
       " 'bull': 237,\n",
       " 'business': 238,\n",
       " 'but': 239,\n",
       " 'buying': 240,\n",
       " 'by': 241,\n",
       " 'called': 242,\n",
       " 'came': 243,\n",
       " 'can': 244,\n",
       " 'canvas': 245,\n",
       " 'canvases': 246,\n",
       " 'cards': 247,\n",
       " 'care': 248,\n",
       " 'career': 249,\n",
       " 'caught': 250,\n",
       " 'central': 251,\n",
       " 'chair': 252,\n",
       " 'chap': 253,\n",
       " 'characteristic': 254,\n",
       " 'charming': 255,\n",
       " 'cheap': 256,\n",
       " 'check': 257,\n",
       " 'cheeks': 258,\n",
       " 'chest': 259,\n",
       " 'chimney-piece': 260,\n",
       " 'chucked': 261,\n",
       " 'cigar': 262,\n",
       " 'cigarette': 263,\n",
       " 'cigars': 264,\n",
       " 'circulation': 265,\n",
       " 'circumstance': 266,\n",
       " 'circus-clown': 267,\n",
       " 'claimed': 268,\n",
       " 'clasping': 269,\n",
       " 'clear': 270,\n",
       " 'cleverer': 271,\n",
       " 'close': 272,\n",
       " 'clue': 273,\n",
       " 'coat': 274,\n",
       " 'collapsed': 275,\n",
       " 'colour': 276,\n",
       " 'come': 277,\n",
       " 'comfortable': 278,\n",
       " 'coming': 279,\n",
       " 'companion': 280,\n",
       " 'compared': 281,\n",
       " 'complex': 282,\n",
       " 'confident': 283,\n",
       " 'congesting': 284,\n",
       " 'conjugal': 285,\n",
       " 'constraint': 286,\n",
       " 'consummate': 287,\n",
       " 'contended': 288,\n",
       " 'continued': 289,\n",
       " 'corner': 290,\n",
       " 'corrected': 291,\n",
       " 'could': 292,\n",
       " 'couldn': 293,\n",
       " 'count': 294,\n",
       " 'countenance': 295,\n",
       " 'couple': 296,\n",
       " 'course': 297,\n",
       " 'covered': 298,\n",
       " 'craft': 299,\n",
       " 'cried': 300,\n",
       " 'crossed': 301,\n",
       " 'crowned': 302,\n",
       " 'crumbled': 303,\n",
       " 'cry': 304,\n",
       " 'cured': 305,\n",
       " 'curiosity': 306,\n",
       " 'curious': 307,\n",
       " 'current': 308,\n",
       " 'curtains': 309,\n",
       " 'd': 310,\n",
       " 'dabble': 311,\n",
       " 'damask': 312,\n",
       " 'dark': 313,\n",
       " 'dashed': 314,\n",
       " 'day': 315,\n",
       " 'days': 316,\n",
       " 'dead': 317,\n",
       " 'deadening': 318,\n",
       " 'dear': 319,\n",
       " 'deep': 320,\n",
       " 'deerhound': 321,\n",
       " 'degree': 322,\n",
       " 'delicate': 323,\n",
       " 'demand': 324,\n",
       " 'denied': 325,\n",
       " 'deploring': 326,\n",
       " 'deprecating': 327,\n",
       " 'deprecatingly': 328,\n",
       " 'desire': 329,\n",
       " 'destroyed': 330,\n",
       " 'destruction': 331,\n",
       " 'desultory': 332,\n",
       " 'detail': 333,\n",
       " 'diagnosis': 334,\n",
       " 'did': 335,\n",
       " 'didn': 336,\n",
       " 'died': 337,\n",
       " 'dim': 338,\n",
       " 'dimmest': 339,\n",
       " 'dingy': 340,\n",
       " 'dining-room': 341,\n",
       " 'disarming': 342,\n",
       " 'discovery': 343,\n",
       " 'discrimination': 344,\n",
       " 'discussion': 345,\n",
       " 'disdain': 346,\n",
       " 'disdained': 347,\n",
       " 'disease': 348,\n",
       " 'disguised': 349,\n",
       " 'display': 350,\n",
       " 'dissatisfied': 351,\n",
       " 'distinguished': 352,\n",
       " 'distract': 353,\n",
       " 'divert': 354,\n",
       " 'do': 355,\n",
       " 'doesn': 356,\n",
       " 'doing': 357,\n",
       " 'domestic': 358,\n",
       " 'don': 359,\n",
       " 'done': 360,\n",
       " 'donkey': 361,\n",
       " 'down': 362,\n",
       " 'dozen': 363,\n",
       " 'dragged': 364,\n",
       " 'drawing-room': 365,\n",
       " 'drawing-rooms': 366,\n",
       " 'drawn': 367,\n",
       " 'dress-closets': 368,\n",
       " 'drew': 369,\n",
       " 'dropped': 370,\n",
       " 'each': 371,\n",
       " 'earth': 372,\n",
       " 'ease': 373,\n",
       " 'easel': 374,\n",
       " 'easy': 375,\n",
       " 'echoed': 376,\n",
       " 'economy': 377,\n",
       " 'effect': 378,\n",
       " 'effects': 379,\n",
       " 'efforts': 380,\n",
       " 'egregious': 381,\n",
       " 'eighteenth-century': 382,\n",
       " 'elbow': 383,\n",
       " 'elegant': 384,\n",
       " 'else': 385,\n",
       " 'embarrassed': 386,\n",
       " 'enabled': 387,\n",
       " 'end': 388,\n",
       " 'endless': 389,\n",
       " 'enjoy': 390,\n",
       " 'enlightenment': 391,\n",
       " 'enough': 392,\n",
       " 'ensuing': 393,\n",
       " 'equally': 394,\n",
       " 'equanimity': 395,\n",
       " 'escape': 396,\n",
       " 'established': 397,\n",
       " 'etching': 398,\n",
       " 'even': 399,\n",
       " 'event': 400,\n",
       " 'ever': 401,\n",
       " 'everlasting': 402,\n",
       " 'every': 403,\n",
       " 'exasperated': 404,\n",
       " 'except': 405,\n",
       " 'excuse': 406,\n",
       " 'excusing': 407,\n",
       " 'existed': 408,\n",
       " 'expected': 409,\n",
       " 'exquisite': 410,\n",
       " 'exquisitely': 411,\n",
       " 'extenuation': 412,\n",
       " 'exterminating': 413,\n",
       " 'extracting': 414,\n",
       " 'eye': 415,\n",
       " 'eyebrows': 416,\n",
       " 'eyes': 417,\n",
       " 'face': 418,\n",
       " 'faces': 419,\n",
       " 'fact': 420,\n",
       " 'faded': 421,\n",
       " 'failed': 422,\n",
       " 'failure': 423,\n",
       " 'fair': 424,\n",
       " 'faith': 425,\n",
       " 'false': 426,\n",
       " 'familiar': 427,\n",
       " 'famille-verte': 428,\n",
       " 'fancy': 429,\n",
       " 'fashionable': 430,\n",
       " 'fate': 431,\n",
       " 'feather': 432,\n",
       " 'feet': 433,\n",
       " 'fell': 434,\n",
       " 'fellow': 435,\n",
       " 'felt': 436,\n",
       " 'few': 437,\n",
       " 'fewer': 438,\n",
       " 'finality': 439,\n",
       " 'find': 440,\n",
       " 'fingers': 441,\n",
       " 'first': 442,\n",
       " 'fit': 443,\n",
       " 'fitting': 444,\n",
       " 'five': 445,\n",
       " 'flash': 446,\n",
       " 'flashed': 447,\n",
       " 'florid': 448,\n",
       " 'flowers': 449,\n",
       " 'fluently': 450,\n",
       " 'flung': 451,\n",
       " 'follow': 452,\n",
       " 'followed': 453,\n",
       " 'fond': 454,\n",
       " 'footstep': 455,\n",
       " 'for': 456,\n",
       " 'forced': 457,\n",
       " 'forcing': 458,\n",
       " 'forehead': 459,\n",
       " 'foreign': 460,\n",
       " 'foreseen': 461,\n",
       " 'forgive': 462,\n",
       " 'forgotten': 463,\n",
       " 'form': 464,\n",
       " 'formed': 465,\n",
       " 'forming': 466,\n",
       " 'forward': 467,\n",
       " 'fostered': 468,\n",
       " 'found': 469,\n",
       " 'foundations': 470,\n",
       " 'fragment': 471,\n",
       " 'fragments': 472,\n",
       " 'frame': 473,\n",
       " 'frames': 474,\n",
       " 'frequently': 475,\n",
       " 'friend': 476,\n",
       " 'from': 477,\n",
       " 'full': 478,\n",
       " 'fullest': 479,\n",
       " 'furiously': 480,\n",
       " 'furrowed': 481,\n",
       " 'garlanded': 482,\n",
       " 'garlands': 483,\n",
       " 'gave': 484,\n",
       " 'genial': 485,\n",
       " 'genius': 486,\n",
       " 'gesture': 487,\n",
       " 'get': 488,\n",
       " 'getting': 489,\n",
       " 'give': 490,\n",
       " 'given': 491,\n",
       " 'glad': 492,\n",
       " 'glanced': 493,\n",
       " 'glimpse': 494,\n",
       " 'gloried': 495,\n",
       " 'glory': 496,\n",
       " 'go': 497,\n",
       " 'going': 498,\n",
       " 'gone': 499,\n",
       " 'good': 500,\n",
       " 'good-breeding': 501,\n",
       " 'good-humoured': 502,\n",
       " 'got': 503,\n",
       " 'grace': 504,\n",
       " 'gradually': 505,\n",
       " 'gray': 506,\n",
       " 'grayish': 507,\n",
       " 'great': 508,\n",
       " 'greatest': 509,\n",
       " 'greatness': 510,\n",
       " 'grew': 511,\n",
       " 'groping': 512,\n",
       " 'growing': 513,\n",
       " 'had': 514,\n",
       " 'hadn': 515,\n",
       " 'hair': 516,\n",
       " 'half': 517,\n",
       " 'half-light': 518,\n",
       " 'half-mechanically': 519,\n",
       " 'hall': 520,\n",
       " 'hand': 521,\n",
       " 'hands': 522,\n",
       " 'handsome': 523,\n",
       " 'hanging': 524,\n",
       " 'happen': 525,\n",
       " 'happened': 526,\n",
       " 'hard': 527,\n",
       " 'hardly': 528,\n",
       " 'has': 529,\n",
       " 'have': 530,\n",
       " 'haven': 531,\n",
       " 'having': 532,\n",
       " 'he': 533,\n",
       " 'head': 534,\n",
       " 'hear': 535,\n",
       " 'heard': 536,\n",
       " 'heart': 537,\n",
       " 'height': 538,\n",
       " 'her': 539,\n",
       " 'here': 540,\n",
       " 'hermit': 541,\n",
       " 'herself': 542,\n",
       " 'hesitations': 543,\n",
       " 'hide': 544,\n",
       " 'high': 545,\n",
       " 'him': 546,\n",
       " 'himself': 547,\n",
       " 'hint': 548,\n",
       " 'his': 549,\n",
       " 'history': 550,\n",
       " 'holding': 551,\n",
       " 'home': 552,\n",
       " 'honour': 553,\n",
       " 'hooded': 554,\n",
       " 'hostess': 555,\n",
       " 'hot-house': 556,\n",
       " 'hour': 557,\n",
       " 'hours': 558,\n",
       " 'house': 559,\n",
       " 'how': 560,\n",
       " 'hung': 561,\n",
       " 'husband': 562,\n",
       " 'idea': 563,\n",
       " 'idle': 564,\n",
       " 'idling': 565,\n",
       " 'if': 566,\n",
       " 'immediately': 567,\n",
       " 'in': 568,\n",
       " 'incense': 569,\n",
       " 'indifferent': 570,\n",
       " 'inevitable': 571,\n",
       " 'inevitably': 572,\n",
       " 'inflexible': 573,\n",
       " 'insensible': 574,\n",
       " 'insignificant': 575,\n",
       " 'instinctively': 576,\n",
       " 'instructive': 577,\n",
       " 'interesting': 578,\n",
       " 'into': 579,\n",
       " 'ironic': 580,\n",
       " 'irony': 581,\n",
       " 'irrelevance': 582,\n",
       " 'irrevocable': 583,\n",
       " 'is': 584,\n",
       " 'it': 585,\n",
       " 'its': 586,\n",
       " 'itself': 587,\n",
       " 'jardiniere': 588,\n",
       " 'jealousy': 589,\n",
       " 'just': 590,\n",
       " 'keep': 591,\n",
       " 'kept': 592,\n",
       " 'kind': 593,\n",
       " 'knees': 594,\n",
       " 'knew': 595,\n",
       " 'know': 596,\n",
       " 'known': 597,\n",
       " 'laid': 598,\n",
       " 'lair': 599,\n",
       " 'landing': 600,\n",
       " 'language': 601,\n",
       " 'last': 602,\n",
       " 'late': 603,\n",
       " 'later': 604,\n",
       " 'latter': 605,\n",
       " 'laugh': 606,\n",
       " 'laughed': 607,\n",
       " 'lay': 608,\n",
       " 'leading': 609,\n",
       " 'lean': 610,\n",
       " 'learned': 611,\n",
       " 'least': 612,\n",
       " 'leathery': 613,\n",
       " 'leave': 614,\n",
       " 'led': 615,\n",
       " 'left': 616,\n",
       " 'leisure': 617,\n",
       " 'lends': 618,\n",
       " 'lent': 619,\n",
       " 'let': 620,\n",
       " 'lies': 621,\n",
       " 'life': 622,\n",
       " 'life-likeness': 623,\n",
       " 'lift': 624,\n",
       " 'lifted': 625,\n",
       " 'light': 626,\n",
       " 'lightly': 627,\n",
       " 'like': 628,\n",
       " 'liked': 629,\n",
       " 'line': 630,\n",
       " 'lines': 631,\n",
       " 'lingered': 632,\n",
       " 'lips': 633,\n",
       " 'lit': 634,\n",
       " 'little': 635,\n",
       " 'live': 636,\n",
       " 'll': 637,\n",
       " 'loathing': 638,\n",
       " 'long': 639,\n",
       " 'longed': 640,\n",
       " 'longer': 641,\n",
       " 'look': 642,\n",
       " 'looked': 643,\n",
       " 'looking': 644,\n",
       " 'lose': 645,\n",
       " 'loss': 646,\n",
       " 'lounging': 647,\n",
       " 'lovely': 648,\n",
       " 'lucky': 649,\n",
       " 'lump': 650,\n",
       " 'luncheon-table': 651,\n",
       " 'luxury': 652,\n",
       " 'lying': 653,\n",
       " 'made': 654,\n",
       " 'make': 655,\n",
       " 'man': 656,\n",
       " 'manage': 657,\n",
       " 'managed': 658,\n",
       " 'mantel-piece': 659,\n",
       " 'marble': 660,\n",
       " 'married': 661,\n",
       " 'may': 662,\n",
       " 'me': 663,\n",
       " 'meant': 664,\n",
       " 'mediocrity': 665,\n",
       " 'medium': 666,\n",
       " 'mentioned': 667,\n",
       " 'mere': 668,\n",
       " 'merely': 669,\n",
       " 'met': 670,\n",
       " 'might': 671,\n",
       " 'mighty': 672,\n",
       " 'millionaire': 673,\n",
       " 'mine': 674,\n",
       " 'minute': 675,\n",
       " 'minutes': 676,\n",
       " 'mirrors': 677,\n",
       " 'modest': 678,\n",
       " 'modesty': 679,\n",
       " 'moment': 680,\n",
       " 'money': 681,\n",
       " 'monumental': 682,\n",
       " 'mood': 683,\n",
       " 'morbidly': 684,\n",
       " 'more': 685,\n",
       " 'most': 686,\n",
       " 'mourn': 687,\n",
       " 'mourned': 688,\n",
       " 'moustache': 689,\n",
       " 'moved': 690,\n",
       " 'much': 691,\n",
       " 'muddling': 692,\n",
       " 'multiplied': 693,\n",
       " 'murmur': 694,\n",
       " 'muscles': 695,\n",
       " 'must': 696,\n",
       " 'my': 697,\n",
       " 'myself': 698,\n",
       " 'mysterious': 699,\n",
       " 'naive': 700,\n",
       " 'near': 701,\n",
       " 'nearly': 702,\n",
       " 'negatived': 703,\n",
       " 'nervous': 704,\n",
       " 'nervousness': 705,\n",
       " 'neutral': 706,\n",
       " 'never': 707,\n",
       " 'next': 708,\n",
       " 'no': 709,\n",
       " 'none': 710,\n",
       " 'not': 711,\n",
       " 'note': 712,\n",
       " 'nothing': 713,\n",
       " 'now': 714,\n",
       " 'nymphs': 715,\n",
       " 'oak': 716,\n",
       " 'obituary': 717,\n",
       " 'object': 718,\n",
       " 'objects': 719,\n",
       " 'occurred': 720,\n",
       " 'oddly': 721,\n",
       " 'of': 722,\n",
       " 'off': 723,\n",
       " 'often': 724,\n",
       " 'oh': 725,\n",
       " 'old': 726,\n",
       " 'on': 727,\n",
       " 'once': 728,\n",
       " 'one': 729,\n",
       " 'ones': 730,\n",
       " 'only': 731,\n",
       " 'onto': 732,\n",
       " 'open': 733,\n",
       " 'or': 734,\n",
       " 'other': 735,\n",
       " 'our': 736,\n",
       " 'ourselves': 737,\n",
       " 'out': 738,\n",
       " 'outline': 739,\n",
       " 'oval': 740,\n",
       " 'over': 741,\n",
       " 'own': 742,\n",
       " 'packed': 743,\n",
       " 'paid': 744,\n",
       " 'paint': 745,\n",
       " 'painted': 746,\n",
       " 'painter': 747,\n",
       " 'painting': 748,\n",
       " 'pale': 749,\n",
       " 'paled': 750,\n",
       " 'palm-trees': 751,\n",
       " 'panel': 752,\n",
       " 'panelling': 753,\n",
       " 'pardonable': 754,\n",
       " 'pardoned': 755,\n",
       " 'part': 756,\n",
       " 'passages': 757,\n",
       " 'passing': 758,\n",
       " 'past': 759,\n",
       " 'pastels': 760,\n",
       " 'pathos': 761,\n",
       " 'patient': 762,\n",
       " 'people': 763,\n",
       " 'perceptible': 764,\n",
       " 'perfect': 765,\n",
       " 'persistence': 766,\n",
       " 'persuasively': 767,\n",
       " 'phrase': 768,\n",
       " 'picture': 769,\n",
       " 'pictures': 770,\n",
       " 'pines': 771,\n",
       " 'pink': 772,\n",
       " 'place': 773,\n",
       " 'placed': 774,\n",
       " 'plain': 775,\n",
       " 'platitudes': 776,\n",
       " 'pleased': 777,\n",
       " 'pockets': 778,\n",
       " 'point': 779,\n",
       " 'poised': 780,\n",
       " 'poor': 781,\n",
       " 'portrait': 782,\n",
       " 'posing': 783,\n",
       " 'possessed': 784,\n",
       " 'poverty': 785,\n",
       " 'predicted': 786,\n",
       " 'preliminary': 787,\n",
       " 'presenting': 788,\n",
       " 'prestidigitation': 789,\n",
       " 'pretty': 790,\n",
       " 'previous': 791,\n",
       " 'price': 792,\n",
       " 'pride': 793,\n",
       " 'princely': 794,\n",
       " 'prism': 795,\n",
       " 'problem': 796,\n",
       " 'proclaiming': 797,\n",
       " 'prodigious': 798,\n",
       " 'profusion': 799,\n",
       " 'protest': 800,\n",
       " 'prove': 801,\n",
       " 'public': 802,\n",
       " 'purblind': 803,\n",
       " 'purely': 804,\n",
       " 'pushed': 805,\n",
       " 'put': 806,\n",
       " 'qualities': 807,\n",
       " 'quality': 808,\n",
       " 'queerly': 809,\n",
       " 'question': 810,\n",
       " 'quickly': 811,\n",
       " 'quietly': 812,\n",
       " 'quite': 813,\n",
       " 'quote': 814,\n",
       " 'rain': 815,\n",
       " 'raised': 816,\n",
       " 'random': 817,\n",
       " 'rather': 818,\n",
       " 're': 819,\n",
       " 'real': 820,\n",
       " 'really': 821,\n",
       " 'reared': 822,\n",
       " 'reason': 823,\n",
       " 'reassurance': 824,\n",
       " 'recovering': 825,\n",
       " 'recreated': 826,\n",
       " 'reflected': 827,\n",
       " 'reflection': 828,\n",
       " 'regrets': 829,\n",
       " 'relatively': 830,\n",
       " 'remained': 831,\n",
       " 'remember': 832,\n",
       " 'reminded': 833,\n",
       " 'repeating': 834,\n",
       " 'represented': 835,\n",
       " 'reproduction': 836,\n",
       " 'resented': 837,\n",
       " 'resolve': 838,\n",
       " 'resources': 839,\n",
       " 'rest': 840,\n",
       " 'rich': 841,\n",
       " 'ridiculous': 842,\n",
       " 'robbed': 843,\n",
       " 'romantic': 844,\n",
       " 'room': 845,\n",
       " 'rose': 846,\n",
       " 'rs': 847,\n",
       " 'rule': 848,\n",
       " 'run': 849,\n",
       " 's': 850,\n",
       " 'said': 851,\n",
       " 'same': 852,\n",
       " 'satisfaction': 853,\n",
       " 'savour': 854,\n",
       " 'saw': 855,\n",
       " 'say': 856,\n",
       " 'saying': 857,\n",
       " 'says': 858,\n",
       " 'scorn': 859,\n",
       " 'scornful': 860,\n",
       " 'secret': 861,\n",
       " 'see': 862,\n",
       " 'seemed': 863,\n",
       " 'seen': 864,\n",
       " 'self-confident': 865,\n",
       " 'send': 866,\n",
       " 'sensation': 867,\n",
       " 'sensitive': 868,\n",
       " 'sent': 869,\n",
       " 'serious': 870,\n",
       " 'set': 871,\n",
       " 'sex': 872,\n",
       " 'shade': 873,\n",
       " 'shaking': 874,\n",
       " 'shall': 875,\n",
       " 'she': 876,\n",
       " 'shirked': 877,\n",
       " 'short': 878,\n",
       " 'should': 879,\n",
       " 'shoulder': 880,\n",
       " 'shoulders': 881,\n",
       " 'show': 882,\n",
       " 'showed': 883,\n",
       " 'showy': 884,\n",
       " 'shrug': 885,\n",
       " 'shrugged': 886,\n",
       " 'sight': 887,\n",
       " 'sign': 888,\n",
       " 'silent': 889,\n",
       " 'silver': 890,\n",
       " 'similar': 891,\n",
       " 'simpleton': 892,\n",
       " 'simplifications': 893,\n",
       " 'simply': 894,\n",
       " 'since': 895,\n",
       " 'single': 896,\n",
       " 'sitter': 897,\n",
       " 'sitters': 898,\n",
       " 'sketch': 899,\n",
       " 'skill': 900,\n",
       " 'slight': 901,\n",
       " 'slightly': 902,\n",
       " 'slowly': 903,\n",
       " 'small': 904,\n",
       " 'smile': 905,\n",
       " 'smiling': 906,\n",
       " 'sneer': 907,\n",
       " 'so': 908,\n",
       " 'solace': 909,\n",
       " 'some': 910,\n",
       " 'somebody': 911,\n",
       " 'something': 912,\n",
       " 'spacious': 913,\n",
       " 'spaniel': 914,\n",
       " 'speaking-tubes': 915,\n",
       " 'speculations': 916,\n",
       " 'spite': 917,\n",
       " 'splash': 918,\n",
       " 'square': 919,\n",
       " 'stairs': 920,\n",
       " 'stammer': 921,\n",
       " 'stand': 922,\n",
       " 'standing': 923,\n",
       " 'started': 924,\n",
       " 'stay': 925,\n",
       " 'still': 926,\n",
       " 'stocked': 927,\n",
       " 'stood': 928,\n",
       " 'stopped': 929,\n",
       " 'stopping': 930,\n",
       " 'straddling': 931,\n",
       " 'straight': 932,\n",
       " 'strain': 933,\n",
       " 'straining': 934,\n",
       " 'strange': 935,\n",
       " 'straw': 936,\n",
       " 'stream': 937,\n",
       " 'stroke': 938,\n",
       " 'strokes': 939,\n",
       " 'strolled': 940,\n",
       " 'strongest': 941,\n",
       " 'strongly': 942,\n",
       " 'struck': 943,\n",
       " 'studio': 944,\n",
       " 'stuff': 945,\n",
       " 'subject': 946,\n",
       " 'substantial': 947,\n",
       " 'suburban': 948,\n",
       " 'such': 949,\n",
       " 'suddenly': 950,\n",
       " 'suffered': 951,\n",
       " 'sugar': 952,\n",
       " 'suggested': 953,\n",
       " 'sunburn': 954,\n",
       " 'sunburnt': 955,\n",
       " 'sunlit': 956,\n",
       " 'superb': 957,\n",
       " 'sure': 958,\n",
       " 'surest': 959,\n",
       " 'surface': 960,\n",
       " 'surprise': 961,\n",
       " 'surprised': 962,\n",
       " 'surrounded': 963,\n",
       " 'suspected': 964,\n",
       " 'sweetly': 965,\n",
       " 'sweetness': 966,\n",
       " 'swelling': 967,\n",
       " 'swept': 968,\n",
       " 'swum': 969,\n",
       " 't': 970,\n",
       " 'table': 971,\n",
       " 'take': 972,\n",
       " 'taken': 973,\n",
       " 'talking': 974,\n",
       " 'tea': 975,\n",
       " 'tears': 976,\n",
       " 'technicalities': 977,\n",
       " 'technique': 978,\n",
       " 'tell': 979,\n",
       " 'tells': 980,\n",
       " 'tempting': 981,\n",
       " 'terra-cotta': 982,\n",
       " 'terrace': 983,\n",
       " 'terraces': 984,\n",
       " 'terribly': 985,\n",
       " 'than': 986,\n",
       " 'that': 987,\n",
       " 'the': 988,\n",
       " 'their': 989,\n",
       " 'them': 990,\n",
       " 'then': 991,\n",
       " 'there': 992,\n",
       " 'therefore': 993,\n",
       " 'they': 994,\n",
       " 'thin': 995,\n",
       " 'thing': 996,\n",
       " 'things': 997,\n",
       " 'think': 998,\n",
       " 'this': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the output above, the dictionary contains individual \n",
    "# tokens associated with unique integer labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is the complete tokenizer class, containing \n",
    "# the following steps ->\n",
    "\n",
    "\n",
    "# Step 1: Store the vocabulary as a class attribute for \n",
    "# access in the encode and decode methods\n",
    "    \n",
    "# Step 2: Create an inverse vocabulary that maps token IDs \n",
    "# back to the original text tokens\n",
    "\n",
    "# Step 3: Process input text into token IDs\n",
    "\n",
    "# Step 4: Convert token IDs back into text\n",
    "\n",
    "# Step 5: Replace spaces before the specified punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code above prints the token IDs of the words passed in\n",
    "# as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try to decode these ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have implemented the SimpleTokenizerV1 class \n",
    "# successfully, lets add some special tokens, like end of text\n",
    "# token and the unknown token. Unknown token is important as \n",
    "# by adding this token, we can even tokenize the words not\n",
    "# in the our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same changes in the SimpleTokenizerV1 class \n",
    "# this class now assigns unknown words the unknown token and\n",
    "# replaces spaces before with specified punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# although this approach works, this is not how the inputs \n",
    "# of the GPT models are tokenized. Instead, a special technique\n",
    "# called byte pair encoding is used.\n",
    "# BPE is a data compression and tokenization algorithm \n",
    "# that is used to reduce the size of text data and break \n",
    "# down words into subword units (common in NLP).\n",
    "# tiktoken is the go to library for byte pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to insall tiktoken, run the following command->\n",
    "# pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can initialize the byte pair encoding from tiktoken \n",
    "# as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us try to decode the above IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readind the text again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we remove the first 50 tokens from the dataset for \n",
    "# demonstration purposes as it  \n",
    "# results in a slightly more interesting text passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create two variables x and y to store the \n",
    "# input-target pairs for the next word prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4 #length of the input\n",
    "\n",
    "# The context_size of 4 means that the model is trained \n",
    "# to look at a sequence of 4 words (or tokens) \n",
    "# to predict the next word in the sequence. \n",
    "# The input x is the first 4 tokens [1, 2, 3, 4], and the \n",
    "# target y is the next 4 tokens [2, 3, 4, 5]\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create the next word prediction task as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything left of the arrow (---->) refers to the input \n",
    "# an LLM would receive, and the token\n",
    "# ID on the right side of the arrow represents the target \n",
    "# token ID that the LLM is supposed to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and --------->  established\n",
      " and established --------->  himself\n",
      " and established himself --------->  in\n",
      " and established himself in --------->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), '--------->', tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will implement an efficient data loader that\n",
    "# iterates over the input dataset and returns the inputs \n",
    "# and targets as PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implementation will have the following steps->\n",
    "\n",
    "# Step 1: Tokenize the entire text\n",
    "    \n",
    "# Step 2: Use a sliding window to chunk the book into \n",
    "# overlapping sequences of max_length\n",
    "\n",
    "# Step 3: Return the total number of rows in the dataset\n",
    "\n",
    "# Step 4: Return a single row from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we convert dataloader into a python iterator to fetch\n",
    "# the next entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cpu\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first_batch variable contains two tensors: the first \n",
    "# tensor stores the input token IDs,\n",
    "# and the second tensor stores the target token IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the second batch's token IDs are\n",
    "#  shifted by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code shows how we can use the dataloaders for\n",
    "# batch size greater then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we move on to creating token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for illustration purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as of now these values are random but these will be\n",
    "# optimized when we train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embedding layer is essentially a look-up operation \n",
    "# that retrieves rows from the embedding layer's weight matrix \n",
    "# via a token ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we now consider more realistic and useful embedding sizes \n",
    "# and encode the input tokens into a 256-dimensional vector \n",
    "# representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the token_embedding_layer above, if we sample data from \n",
    "# the data loader, we embed each token in each batch into \n",
    "# a 256-dimensional vector. If we have a batch size of 8\n",
    "# with four tokens each, the result will be an 8 x 4 x 256 \n",
    "# tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a GPT model's absolute embedding approach, we just need to \n",
    "# create another embedding layer that has the same dimension\n",
    "# as the token_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the positional embedding tensor consists of four \n",
    "# 256-dimensional vectors. We can now add these directly to \n",
    "# the token embeddings, where PyTorch will add the 4x256-\n",
    "# dimensional pos_embeddings tensor to each 4x256-dimensional \n",
    "# token embedding tensor in each of the 8 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example sentence - your journey starts with one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following plots help to visualize the words \n",
    "# in the form of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Corresponding words\n",
    "words = ['Your', 'journey', 'starts', 'with', 'one', 'step']\n",
    "\n",
    "# Extract x, y, z coordinates\n",
    "x_coords = inputs[:, 0].numpy()\n",
    "y_coords = inputs[:, 1].numpy()\n",
    "z_coords = inputs[:, 2].numpy()\n",
    "\n",
    "# Create 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot each point and annotate with corresponding word\n",
    "for x, y, z, word in zip(x_coords, y_coords, z_coords, words):\n",
    "    ax.scatter(x, y, z)\n",
    "    ax.text(x, y, z, word, fontsize=10)\n",
    "\n",
    "# Set labels for axes\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.title('3D Plot of Word Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 3D plot with vectors from origin to each point, using different colors\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define a list of colors for the vectors\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y']\n",
    "\n",
    "# Plot each vector with a different color and annotate with the corresponding word\n",
    "for (x, y, z, word, color) in zip(x_coords, y_coords, z_coords, words, colors):\n",
    "    # Draw vector from origin to the point (x, y, z) with specified color and smaller arrow length ratio\n",
    "    ax.quiver(0, 0, 0, x, y, z, color=color, arrow_length_ratio=0.05)\n",
    "    ax.text(x, y, z, word, fontsize=10, color=color)\n",
    "\n",
    "# Set labels for axes\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "# Set plot limits to keep arrows within the plot boundaries\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_zlim([0, 1])\n",
    "\n",
    "plt.title('3D Plot of Word Embeddings with Colored Vectors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second input token serves as the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we normalize these attention scores. normalization \n",
    "# will allow us to obtain attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using softmax for normalization is better, it offers \n",
    "# more favorable gradient properties during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The context vector z(2)is calculated as a weighted sum of all\n",
    "# input vectors. This involves multiplying each input vector\n",
    "# by its corresponding attention weigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # 2nd input token is the query\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can achieve the same results by using matrix\n",
    "# multiplication and it is faster then 2 for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim = -1 instructs the softmax to normalize along the last \n",
    "# dimension of the attn_scores tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we implement self attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a few variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] #A\n",
    "d_in = inputs.shape[1] #B\n",
    "d_out = 2 #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we initialize the three weight metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n"
     ]
    }
   ],
   "source": [
    "print(W_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we compute the key, query and the value vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see based on the output for the query, this results \n",
    "# in a 2-dimensional vector. This is because we set the number \n",
    "# of columns of the corresponding weight matrix, via d_out, to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are computing the attention score w22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1] #A\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the above cell, we are dividing by square root of \n",
    "# dimension. why? because The softmax function is sensitive \n",
    "# to the magnitudes of its inputs. When the inputs are large, \n",
    "# the differences between the exponential values of each input \n",
    "# become much more pronounced. This causes the softmax output \n",
    "# to become \"peaky,\" where the highest value receives almost \n",
    "# all the probability mass, and the rest receive very little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we will implement a compact self attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__() # initializes trainable weights\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can improve the SelfAttention_v1 implementation further \n",
    "# by utilizing PyTorch's nn.Linear layers, which effectively \n",
    "# perform matrix multiplication when the bias units are disabled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's move to causal attention. Here, we hide the future words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs) #A\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use PyTorch's tril function to create a mask where the \n",
    "# values above the diagonal are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we simply multiply this mask with the attention weights \n",
    "# to zero out the values above the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights*mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now again have to renormalize the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another approach could be that we make a mask of 1s above \n",
    "# the diagonal and the replacing these 1s with negative \n",
    "# infinity values. this is because the softmax function treats \n",
    "# negative infinity as zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying softmax, we see that -inf values become 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process ensures no information leakage from masked \n",
    "# tokens, focusing the model solely on the intended data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before calculating the context vectors, we will be masking\n",
    "# additional attention weights with dropout. this will be\n",
    "# useful in reducing overfitting when training llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) #A\n",
    "example = torch.ones(6, 6) #B\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When applying dropout to an attention weight matrix with a \n",
    "# rate of 50%, half of the elements in the matrix are randomly \n",
    "# set to zero. \n",
    "\n",
    "# To compensate for the reduction in active elements, the \n",
    "# values of the remaining elements in the matrix are \n",
    "# scaled up by a factor of 1/0.5 =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will implement a compact causal attention class \n",
    "# which will contain the causal attention and dropout \n",
    "# modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the class will involve the following steps->\n",
    "\n",
    "# Step 1: Compared to the previous SelfAttention_v1 class, we \n",
    "# added a dropout layer.\n",
    "    \n",
    "# Step 2:  We transpose dimensions 1 and 2, keeping the batch \n",
    "# dimension at the first position (0).\n",
    "\n",
    "# Step 3: In PyTorch, operations with a trailing underscore \n",
    "# are performed in-place, avoiding unnecessary memory copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will implement a multi-head attention class by \n",
    "# implementing several of such causal attention mechanisms \n",
    "# in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we use this MultiHeadAttentionWrapper class with two \n",
    "# attention heads (via num_heads=2) and CausalAttention \n",
    "# output dimension d_out=2, this results in a 4-dimensional \n",
    "# context vectors (d_out*num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the context vectors are exactly same because the input \n",
    "# texts are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we will combine MultiHeadAttentionWrapper and \n",
    "# CausalAttention, into a single MultiHeadAttention class. It \n",
    "# splits the input into multiple heads by reshaping the \n",
    "# projected query, key, and value tensors and then combines\n",
    "# the results from these heads after computing attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573], #A\n",
    "[0.8993, 0.0390, 0.9268, 0.7388],\n",
    "[0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "[[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "[0.4066, 0.2318, 0.4545, 0.9737],\n",
    "[0.4606, 0.5159, 0.4220, 0.5786]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a @ a.transpose(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have implemented multihead attention, we will \n",
    "# move on to implementing a gpt model from scratch to generate \n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is a dummy gpt class,which uses a placeholer\n",
    "# for transformer block and a placeholder for layernorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization using tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create an instance of the dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding has 50,257 dimensions because each of these \n",
    "# dimensions refers to aunique token in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can move on to layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following are the mean and variance before normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to improve readability, we can also turn off \n",
    "# the scientific notation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we encapsulate this process in a PyTorch module that we \n",
    "# can use in the GPT model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scale and shift are two trainable parameters \n",
    "# (of the same dimension as the input) that the LLM \n",
    "# automatically adjusts during training if it is determined that\n",
    "# doing so would improve the model's performance on its training \n",
    "# task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will implement feedforward neural network with \n",
    "# GELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELU function is very similar to the RELU activation \n",
    "# function, but GELU function is differnetiable even at 0. \n",
    "# this smoothness of GELU leads to better optimization \n",
    "# properties during training. GELU also allows for small, \n",
    "# non-zero output for negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GELU , we now implement the small neural network module, \n",
    "# FeedForward, that we will be using in the LLM's transformer \n",
    "# block later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the input and output dimensions of this module are \n",
    "# the same, it internally expands the embedding dimension\n",
    "# into a higher-dimensional space through the first linear layer.\n",
    "\n",
    "# This expansion is followed by a non-linear GELU activation, \n",
    "# and then a contraction back to the original dimension with \n",
    "# the second linear transformation. \n",
    "\n",
    "# Such a design allows for the\n",
    "# exploration of a richer representation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will implement shortcut connections to the feed \n",
    "# forward methord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The code below implements a deep neural network with 5 layers, \n",
    "# each consisting of a Linear layer and a GELU activation \n",
    "# function. \n",
    "\n",
    "# In the forward pass, we iteratively pass the input\n",
    "# through the layers and optionally add the shortcut \n",
    "# connections  if the self.use_shortcut attribute is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's use this code to first initialize a neural network \n",
    "# without shortcut connections. Here, each layer will be \n",
    "# initialized such that it accepts an example with 3 input \n",
    "# values and returns 3 output values. The last layer returns \n",
    "# a single output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following function computes the gradients \n",
    "# in the model's backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have a 33 weight parameter matrix for a given layer. \n",
    "# In that case, this layer will have 33 gradient values, and \n",
    "# we print the mean absolute gradient of these 33 gradient \n",
    "# values to obtain a single gradient value per layer to compare \n",
    "# the gradients between layers more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is evident from the outputs of the above cell, the \n",
    "# gradients become smaller as we progress from the last \n",
    "# layer (layers.4) to the first layer (layers.0), which\n",
    "# is a phenomenon called the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can instantiate a model with skip connections to \n",
    "# tackle this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will code attention and linear layers in a \n",
    "# transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Shortcut connection for attention block\n",
    "\n",
    "# Step 2:  Shortcut connection for feed forward block\n",
    "\n",
    "# Step 3: Add the original input back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasn refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
      "Training completed in 5.24 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"tqdm version:\", tqdm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptweight import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 53.4kiB/s]\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\encoder.json: 100%|| 1.04M/1.04M [00:01<00:00, 577kiB/s] \n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 62.0kiB/s]\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\model.ckpt.data-00000-of-00001: 100%|| 498M/498M [18:13<00:00, 455kiB/s]    \n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 2.13MiB/s]\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\model.ckpt.meta: 100%|| 471k/471k [00:01<00:00, 298kiB/s]  \n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\124M\\vocab.bpe: 100%|| 456k/456k [00:01<00:00, 284kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward the goal, but you also move forward.\n",
      "\n",
      "\"I think there's a lot of people who think that the game is about you, and that's not true. That's not true. It's about you,\" he said. \"\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=50,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will  b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will  b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "from gptweight import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 13.61 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "models\\355M\\model.ckpt.data-00000-of-00001: 100%|| 1.42G/1.42G [59:00<00:00, 401kiB/s]   \n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gptweight import download_and_load_gpt2\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8258950233459474\n",
      "Validation loss: 3.7619200229644774\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my terminal died here due to computational limitations at\n",
    "# my end. someone with sufficient computation resources is \n",
    "# incoraged to run the following cells and see the outputs of\n",
    "# the llm we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      3\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtorch\u001b[49m.manual_seed(\u001b[32m123\u001b[39m)\n\u001b[32m      7\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=\u001b[32m0.00005\u001b[39m, weight_decay=\u001b[32m0.1\u001b[39m)\n\u001b[32m      9\u001b[39m num_epochs = \u001b[32m1\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
